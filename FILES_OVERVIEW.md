# Project Files Overview and Simplification Notes

## 1. What each file does

### Core code (keep)

| File | Role |
|------|------|
| **mrbert/modeling_mrbert.py** | MrBERT model: gate, soft/hard deletion, MrBertForSequenceClassification / MrBertForQuestionAnswering |
| **mrbert/configuration_mrbert.py** | MrBERT config (gate_layer_index, gate_k, etc.) |
| **mrbert/pi_controller.py** | PI controller (adjusts deletion rate) |
| **mrbert/__init__.py** | Package entry; exports MrBertConfig / MrBertModel / MrBertForSequenceClassification / MrBertForQuestionAnswering |
| **train_mrbert.py** | Training entry: MRPC / IMDB / SST-2 / SNLI / TyDi QA; classification and QA; `--log_level`, `--output_result` |

### Diagnostics and logging (recommended to keep)

| File | Role |
|------|------|
| **mrbert/diagnostics.py** | Parameter counts, shape changes, theoretical MACs saved, dropped-token analysis and highlighting; **gate interpretability demo** (`python -m mrbert.diagnostics --sentences "..." --stats`) |

### Experiments and results

| File | Role |
|------|------|
| **latency_benchmark.py** | Measures baseline vs MrBERT inference latency; writes `results/latency_results.json` |
| **scripts/aggregate_results.py** | Reads `train_results.jsonl` + `latency_results.json`, generates **RESULTS.md** |
| **scripts/extract_error_cases.py** | Filters "wrong prediction + high deletion rate" samples (SNLI/TyDi QA), outputs typical errors + dropped tokens |

### Optional / auxiliary

| File | Role | Simplify? |
|------|------|-----------|
| **run_mrbert_example.py** | Minimal example: load MrBERT, run one batch, optional PI | Can remove or fold into README |
| **inspect_data.py** | Inspect dataset source, task, labels, and a few samples (mrpc/imdb/sst2) | Can remove or keep as a data-check tool |
| **run_experiments.sh** | Batch run MRPC / IMDB / SNLI / SST-2 / TyDi QA, write `train_results.jsonl`; **QUICK=1** runs MRPC 200 samples + latency only | Already merged with former run_gpu_small.sh |

### Documentation

| File | Role |
|------|------|
| **README.md** | Project overview, usage, report structure |
| **RESULTS.md** | Generated by aggregate_results.py; experiment table + latency |
| **DATA_README.md** | Data sources and task description (mrpc/imdb/sst2) |
| **GCP_SETUP.md** | GCP/Colab instructions for running experiments |

---

## 2. Simplification suggestions

### Safe to remove or merge (no impact on core)

1. **run_mrbert_example.py**  
   - Role: minimal runnable example.  
   - Suggestion: remove and add a short "one-command training" example in README; or keep if you want a no-training forward-only demo.

2. **inspect_data.py**  
   - Role: inspect raw data.  
   - Suggestion: remove if you no longer need to check samples; otherwise keep as a small utility.

3. **gate_interpretability.py**  
   - **Merged** into `mrbert/diagnostics.py`: use `python -m mrbert.diagnostics --sentences "..." --stats`.

### Already merged

4. **run_gpu_small.sh** is now part of **run_experiments.sh**  
   - Use `QUICK=1 ./run_experiments.sh` for the former "small GPU run + latency".

5. **Docs**  
   - **DATA_README.md**: if README already has a "Data" section, you can condense DATA_README into it and delete DATA_README.

### Better left as-is

- The four .py files under **mrbert/**: core model and config.  
- **train_mrbert.py**: single training entry, keep as is.  
- **mrbert/diagnostics.py**: logging and interpretability; works with train_mrbert `--log_level`.  
- **scripts/aggregate_results.py**, **scripts/extract_error_cases.py**: needed for results and error analysis.  
- **latency_benchmark.py**: source of efficiency numbers.

---

## 3. Recommended minimal layout

```
cs224n_project/
├── mrbert/
│   ├── __init__.py
│   ├── configuration_mrbert.py
│   ├── modeling_mrbert.py
│   ├── pi_controller.py
│   └── diagnostics.py
├── scripts/
│   ├── aggregate_results.py
│   └── extract_error_cases.py
├── results/
│   ├── train_results.jsonl
│   └── latency_results.json
├── train_mrbert.py          # training + log_level
├── latency_benchmark.py
├── run_experiments.sh       # optional; QUICK=1 for small run
├── README.md
├── RESULTS.md               # auto-generated
└── GCP_SETUP.md             # optional
```

**Removed / merged:**  
- `run_gpu_small.sh` → `run_experiments.sh` (`QUICK=1`)  
- `gate_interpretability.py` → `mrbert/diagnostics.py` (`python -m mrbert.diagnostics`)

**Optional to remove:**  
- `run_mrbert_example.py`  
- `inspect_data.py` (if you don’t need to inspect data)  
- `DATA_README.md` (after folding into README)

This keeps the repo to about **8–10** main files with clear roles.
